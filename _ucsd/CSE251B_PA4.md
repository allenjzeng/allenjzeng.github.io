---
layout:      project  # Must be set to project
date:        3 March 2021
title:       Using LSTM Networks to Caption Images on the COCO Dataset
caption:     Inputting an image into the network, and getting a text description of the image as output.
image:
  path:      /assets/thumb/cse251b-4.webp
  srcset:
    678w:    /assets/thumb/cse251b-4.webp
    480w:    /assets/thumb/cse251b-4@480w.webp
    240w:    /assets/thumb/cse251b-4@240w.webp
description: >
  An example input image, some reference "ground truth" captions, and the model's predicted caption.
links:
  - title:   PDF
    url:     /assets/pdf/ucsd/CSE251B_PA4.pdf
featured:    false
sitemap:     true
keywords:
  - Long Short-Term Memory (LSTM)
  - Recurrent Neural Networks (RNN)
  - Image captioning
  - Common Objects in Context (COCO) dataset
  - ResNet50
  - Bleu1 score
  - Bleu4 score
  - Deterministic caption prediction
  - Data augmentation
  - Embedding size
  - Hidden state size
  - Stochastic caption generation
  - Temperature parameter
  - Stacked LSTM architectures
  - Validation loss
  - Test loss
---

Some examples of the captions generated from the model:

![1.webp](/assets/webp/cse251b/1.webp){:.lead width="703" height="671" loading="lazy"}

![2.webp](/assets/webp/cse251b/2.webp){:.lead width="678" height="635" loading="lazy"}

![3.webp](/assets/webp/cse251b/3.webp){:.lead width="691" height="437" loading="lazy"}

![4.webp](/assets/webp/cse251b/4.webp){:.lead width="679" height="723" loading="lazy"}

![5.webp](/assets/webp/cse251b/5.webp){:.lead width="684" height="312" loading="lazy"}

Using LSTM Networks to Caption Images on the COCO Dataset
: [PDF](/assets/pdf/ucsd/CSE251B_PA4.pdf){:.no-push-state}

<object data="/assets/pdf/ucsd/CSE251B_PA4.pdf" width="100%" height="1000" type="application/pdf"></object>
